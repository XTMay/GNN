#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡é‡è€¦åˆå¸¸æ•°é¢„æµ‹ - å¤šç§GNNæ¡†æ¶æ¯”è¾ƒ
åŸºäºåŸå­å¯¹çº§åˆ«çš„é¢„æµ‹ä»»åŠ¡ï¼Œä½¿ç”¨ä¸åŒå¤æ‚åº¦çš„å›¾ç¥ç»ç½‘ç»œæ¶æ„

åŒ…å«çš„æ¨¡å‹ï¼š
1. åŸºç¡€åŸå­å¯¹MLP (Simple)
2. å›¾å·ç§¯ç½‘ç»œ (GCN)
3. å›¾æ³¨æ„åŠ›ç½‘ç»œ (GAT)
4. Graph Transformer
5. æ¶ˆæ¯ä¼ é€’ç½‘ç»œ (MPNN)
6. é›†æˆå­¦ä¹ æ–¹æ³•
7. 3Då‡ ä½•å¢å¼ºæ¨¡å‹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam, AdamW
from torch.utils.data import DataLoader, Dataset
from torch_geometric.nn import (GCNConv, GATConv, TransformerConv, NNConv,
                               global_mean_pool, global_max_pool, global_add_pool,
                               BatchNorm, LayerNorm)
from torch_geometric.data import Data, Batch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler
from sklearn.decomposition import PCA
import seaborn as sns
import os
import time
import warnings
from collections import defaultdict
warnings.filterwarnings('ignore')


# =============================================================================
# 1. åŸºç¡€åŸå­å¯¹MLPæ¨¡å‹ (ç®€åŒ–ç‰ˆæœ¬)
# =============================================================================
class SimpleAtomPairMLP(nn.Module):
    """åŸºç¡€åŸå­å¯¹MLPæ¨¡å‹"""

    def __init__(self, num_features=10, hidden_dim=64):
        super(SimpleAtomPairMLP, self).__init__()

        self.mlp = nn.Sequential(
            nn.Linear(num_features, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, 1)
        )

    def forward(self, pair_features):
        return self.mlp(pair_features)


# =============================================================================
# 2. å›¾å·ç§¯ç½‘ç»œ (GCN) æ¨¡å‹
# =============================================================================
class CouplingGCN(nn.Module):
    """åŸºäºGCNçš„æ ‡é‡è€¦åˆå¸¸æ•°é¢„æµ‹æ¨¡å‹"""

    def __init__(self, num_atom_features, num_pair_features, hidden_dim=128, num_layers=3):
        super(CouplingGCN, self).__init__()

        self.num_layers = num_layers

        # åŸå­ç‰¹å¾å¤„ç†
        self.atom_embedding = nn.Linear(num_atom_features, hidden_dim)

        # GCNå±‚
        self.convs = nn.ModuleList()
        self.batch_norms = nn.ModuleList()

        for i in range(num_layers):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))
            self.batch_norms.append(BatchNorm(hidden_dim))

        # åŸå­å¯¹ç‰¹å¾èåˆ
        self.pair_mlp = nn.Sequential(
            nn.Linear(hidden_dim * 2 + num_pair_features, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, 1)
        )

    def forward(self, atom_features, edge_index, pair_indices, pair_features):
        # åŸå­ç‰¹å¾åµŒå…¥
        x = self.atom_embedding(atom_features)

        # GCNå±‚
        for i in range(self.num_layers):
            x = self.convs[i](x, edge_index)
            x = self.batch_norms[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=0.2, training=self.training)

        # æå–åŸå­å¯¹ç‰¹å¾
        atom_pair_0 = x[pair_indices[:, 0]]  # ç¬¬ä¸€ä¸ªåŸå­
        atom_pair_1 = x[pair_indices[:, 1]]  # ç¬¬äºŒä¸ªåŸå­

        # æ‹¼æ¥åŸå­å¯¹ç‰¹å¾
        combined_features = torch.cat([atom_pair_0, atom_pair_1, pair_features], dim=1)

        # é¢„æµ‹è€¦åˆå¸¸æ•°
        return self.pair_mlp(combined_features)


# =============================================================================
# 3. å›¾æ³¨æ„åŠ›ç½‘ç»œ (GAT) æ¨¡å‹
# =============================================================================
class CouplingGAT(nn.Module):
    """åŸºäºGATçš„æ ‡é‡è€¦åˆå¸¸æ•°é¢„æµ‹æ¨¡å‹"""

    def __init__(self, num_atom_features, num_pair_features, hidden_dim=128, num_layers=3, heads=4):
        super(CouplingGAT, self).__init__()

        self.num_layers = num_layers
        self.heads = heads

        # åŸå­ç‰¹å¾å¤„ç†
        self.atom_embedding = nn.Linear(num_atom_features, hidden_dim)

        # GATå±‚
        self.convs = nn.ModuleList()
        self.batch_norms = nn.ModuleList()

        # ç¬¬ä¸€å±‚
        self.convs.append(GATConv(hidden_dim, hidden_dim // heads, heads=heads, dropout=0.2))
        self.batch_norms.append(BatchNorm(hidden_dim))

        # ä¸­é—´å±‚
        for i in range(num_layers - 2):
            self.convs.append(GATConv(hidden_dim, hidden_dim // heads, heads=heads, dropout=0.2))
            self.batch_norms.append(BatchNorm(hidden_dim))

        # æœ€åä¸€å±‚
        if num_layers > 1:
            self.convs.append(GATConv(hidden_dim, hidden_dim, heads=1, dropout=0.2))
            self.batch_norms.append(BatchNorm(hidden_dim))

        # åŸå­å¯¹é¢„æµ‹å±‚
        self.pair_mlp = nn.Sequential(
            nn.Linear(hidden_dim * 2 + num_pair_features, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, 1)
        )

    def forward(self, atom_features, edge_index, pair_indices, pair_features):
        x = self.atom_embedding(atom_features)

        # GATå±‚
        for i in range(self.num_layers):
            x = self.convs[i](x, edge_index)
            x = self.batch_norms[i](x)
            x = F.elu(x)  # GATé€šå¸¸ä½¿ç”¨ELU
            x = F.dropout(x, p=0.2, training=self.training)

        # åŸå­å¯¹ç‰¹å¾
        atom_pair_0 = x[pair_indices[:, 0]]
        atom_pair_1 = x[pair_indices[:, 1]]

        combined_features = torch.cat([atom_pair_0, atom_pair_1, pair_features], dim=1)

        return self.pair_mlp(combined_features)


# =============================================================================
# 4. Graph Transformer æ¨¡å‹
# =============================================================================
class CouplingTransformer(nn.Module):
    """åŸºäºTransformerçš„æ ‡é‡è€¦åˆå¸¸æ•°é¢„æµ‹æ¨¡å‹"""

    def __init__(self, num_atom_features, num_pair_features, hidden_dim=128, num_layers=3, heads=8):
        super(CouplingTransformer, self).__init__()

        self.num_layers = num_layers
        self.hidden_dim = hidden_dim

        # åŸå­ç‰¹å¾åµŒå…¥
        self.atom_embedding = nn.Linear(num_atom_features, hidden_dim)

        # Transformerå±‚
        self.transformers = nn.ModuleList()
        self.layer_norms = nn.ModuleList()

        for _ in range(num_layers):
            self.transformers.append(
                TransformerConv(hidden_dim, hidden_dim // heads, heads=heads, dropout=0.2)
            )
            self.layer_norms.append(LayerNorm(hidden_dim))

        # åŸå­å¯¹é¢„æµ‹å±‚
        self.pair_mlp = nn.Sequential(
            nn.Linear(hidden_dim * 2 + num_pair_features, hidden_dim * 2),
            nn.GELU(),  # Transformeré€šå¸¸ä½¿ç”¨GELU
            nn.Dropout(0.3),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, 1)
        )

    def forward(self, atom_features, edge_index, pair_indices, pair_features):
        x = self.atom_embedding(atom_features)

        # Transformerå±‚
        for i in range(self.num_layers):
            residual = x
            x = self.transformers[i](x, edge_index)
            x = self.layer_norms[i](x)
            x = F.gelu(x + residual)  # æ®‹å·®è¿æ¥
            x = F.dropout(x, p=0.2, training=self.training)

        # åŸå­å¯¹ç‰¹å¾
        atom_pair_0 = x[pair_indices[:, 0]]
        atom_pair_1 = x[pair_indices[:, 1]]

        combined_features = torch.cat([atom_pair_0, atom_pair_1, pair_features], dim=1)

        return self.pair_mlp(combined_features)


# =============================================================================
# 5. æ¶ˆæ¯ä¼ é€’ç¥ç»ç½‘ç»œ (MPNN)
# =============================================================================
class CouplingMPNN(nn.Module):
    """åŸºäºMPNNçš„æ ‡é‡è€¦åˆå¸¸æ•°é¢„æµ‹æ¨¡å‹"""

    def __init__(self, num_atom_features, num_pair_features, hidden_dim=128, num_layers=3):
        super(CouplingMPNN, self).__init__()

        self.num_layers = num_layers

        # åŸå­ç‰¹å¾åµŒå…¥
        self.atom_embedding = nn.Linear(num_atom_features, hidden_dim)

        # è¾¹ç‰¹å¾ç½‘ç»œ
        edge_network = nn.Sequential(
            nn.Linear(1, hidden_dim),  # å‡è®¾è¾¹ç‰¹å¾æ˜¯1ç»´(è·ç¦»)
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim * hidden_dim)
        )

        # MPNNå±‚
        self.convs = nn.ModuleList()
        self.batch_norms = nn.ModuleList()

        for _ in range(num_layers):
            self.convs.append(NNConv(hidden_dim, hidden_dim, edge_network))
            self.batch_norms.append(BatchNorm(hidden_dim))

        # åŸå­å¯¹é¢„æµ‹å±‚
        self.pair_mlp = nn.Sequential(
            nn.Linear(hidden_dim * 2 + num_pair_features, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, 1)
        )

    def forward(self, atom_features, edge_index, edge_attr, pair_indices, pair_features):
        x = self.atom_embedding(atom_features)

        # MPNNå±‚
        for i in range(self.num_layers):
            x = self.convs[i](x, edge_index, edge_attr)
            x = self.batch_norms[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=0.2, training=self.training)

        # åŸå­å¯¹ç‰¹å¾
        atom_pair_0 = x[pair_indices[:, 0]]
        atom_pair_1 = x[pair_indices[:, 1]]

        combined_features = torch.cat([atom_pair_0, atom_pair_1, pair_features], dim=1)

        return self.pair_mlp(combined_features)


# =============================================================================
# 6. 3Då‡ ä½•å¢å¼ºæ¨¡å‹
# =============================================================================
class Coupling3DGCN(nn.Module):
    """åŸºäº3Då‡ ä½•ä¿¡æ¯å¢å¼ºçš„GCNæ¨¡å‹"""

    def __init__(self, num_atom_features, num_pair_features, hidden_dim=128, num_layers=3):
        super(Coupling3DGCN, self).__init__()

        self.num_layers = num_layers

        # åŸå­ç‰¹å¾å¤„ç†
        self.atom_embedding = nn.Linear(num_atom_features, hidden_dim)

        # 3Då‡ ä½•ç‰¹å¾å¤„ç†
        self.geometry_mlp = nn.Sequential(
            nn.Linear(3, hidden_dim // 4),  # 3Dåæ ‡
            nn.ReLU(),
            nn.Linear(hidden_dim // 4, hidden_dim // 4)
        )

        # GCNå±‚
        self.convs = nn.ModuleList()
        self.batch_norms = nn.ModuleList()

        for i in range(num_layers):
            input_dim = hidden_dim + hidden_dim // 4 if i == 0 else hidden_dim
            self.convs.append(GCNConv(input_dim, hidden_dim))
            self.batch_norms.append(BatchNorm(hidden_dim))

        # åŸå­å¯¹é¢„æµ‹å±‚
        self.pair_mlp = nn.Sequential(
            nn.Linear(hidden_dim * 2 + num_pair_features + 6, hidden_dim * 2),  # +6 for 3D coords
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, 1)
        )

    def forward(self, atom_features, atom_coords, edge_index, pair_indices, pair_features, pair_coords):
        x = self.atom_embedding(atom_features)

        # å¤„ç†3Dåæ ‡
        geom_features = self.geometry_mlp(atom_coords)

        # ç¬¬ä¸€å±‚ï¼šæ‹¼æ¥åŸå­ç‰¹å¾å’Œå‡ ä½•ç‰¹å¾
        x = torch.cat([x, geom_features], dim=1)

        # GCNå±‚
        for i in range(self.num_layers):
            x = self.convs[i](x, edge_index)
            x = self.batch_norms[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=0.2, training=self.training)

        # åŸå­å¯¹ç‰¹å¾
        atom_pair_0 = x[pair_indices[:, 0]]
        atom_pair_1 = x[pair_indices[:, 1]]

        # æ‹¼æ¥åŸå­å¯¹ç‰¹å¾å’Œ3Dåæ ‡
        combined_features = torch.cat([
            atom_pair_0, atom_pair_1, pair_features, pair_coords.flatten(1)
        ], dim=1)

        return self.pair_mlp(combined_features)


# =============================================================================
# 7. é›†æˆå­¦ä¹ æ¨¡å‹
# =============================================================================
class CouplingEnsemble(nn.Module):
    """é›†æˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹å™¨"""

    def __init__(self, num_atom_features, num_pair_features, hidden_dim=128):
        super(CouplingEnsemble, self).__init__()

        # ä¸åŒçš„å­æ¨¡å‹
        self.gcn_model = CouplingGCN(num_atom_features, num_pair_features, hidden_dim, num_layers=3)
        self.gat_model = CouplingGAT(num_atom_features, num_pair_features, hidden_dim, num_layers=2, heads=4)

        # å…ƒå­¦ä¹ å™¨
        self.meta_learner = nn.Sequential(
            nn.Linear(2, 32),  # 2ä¸ªå­æ¨¡å‹çš„è¾“å‡º
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1)
        )

    def forward(self, atom_features, edge_index, pair_indices, pair_features):
        # è·å–å­æ¨¡å‹é¢„æµ‹
        pred1 = self.gcn_model(atom_features, edge_index, pair_indices, pair_features)
        pred2 = self.gat_model(atom_features, edge_index, pair_indices, pair_features)

        # å…ƒå­¦ä¹ å™¨ç»„åˆ
        ensemble_input = torch.cat([pred1, pred2], dim=1)
        final_pred = self.meta_learner(ensemble_input)

        return final_pred


# =============================================================================
# æ•°æ®å¤„ç†ç±»
# =============================================================================
class CouplingGraphDataset(Dataset):
    """ç”¨äºå›¾ç¥ç»ç½‘ç»œçš„æ ‡é‡è€¦åˆå¸¸æ•°æ•°æ®é›†"""

    def __init__(self, data_path, max_samples=5000, use_3d=False):
        self.data_path = data_path
        self.max_samples = max_samples
        self.use_3d = use_3d

        # ç¼–ç å™¨å’Œç¼©æ”¾å™¨
        self.type_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        self.coord_scaler = StandardScaler()

        # åŸå­ç‰¹å¾æ˜ å°„
        self.atom_features = {
            'H': [1, 1.008, 1, 1, 2.20, 0.31],  # åŸå­åºæ•°, è´¨é‡, ä»·ç”µå­, å‘¨æœŸ, ç”µè´Ÿæ€§, åŠå¾„
            'C': [6, 12.01, 4, 2, 2.55, 0.76],
            'N': [7, 14.01, 5, 2, 3.04, 0.71],
            'O': [8, 16.00, 6, 2, 3.44, 0.66],
            'F': [9, 19.00, 7, 2, 3.98, 0.57],
        }

        print(f"åŠ è½½æ ‡é‡è€¦åˆå¸¸æ•°æ•°æ®ï¼Œæ ·æœ¬æ•°: {max_samples}")
        self._load_and_preprocess_data()

    def _load_and_preprocess_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        # åŠ è½½æ•°æ®
        train_df = pd.read_csv(os.path.join(self.data_path, 'train.csv')).head(self.max_samples)
        structures_df = pd.read_csv(os.path.join(self.data_path, 'structures.csv'))

        print(f"åŠ è½½ {len(train_df)} ä¸ªè€¦åˆæ ·æœ¬")

        # é¢„å¤„ç†åˆ†å­å›¾æ•°æ®
        self.graph_data = self._create_graph_data(train_df, structures_df)

        print(f"æˆåŠŸåˆ›å»º {len(self.graph_data)} ä¸ªå›¾æ•°æ®")

    def _create_graph_data(self, train_df, structures_df):
        """åˆ›å»ºå›¾æ•°æ®"""
        graph_data_list = []

        # æŒ‰åˆ†å­åˆ†ç»„
        molecule_groups = train_df.groupby('molecule_name')

        processed_molecules = 0
        for mol_name, coupling_df in molecule_groups:
            if processed_molecules % 1000 == 0:
                print(f"å¤„ç†åˆ†å­: {processed_molecules}")

            # è·å–åˆ†å­ç»“æ„
            mol_structure = structures_df[structures_df['molecule_name'] == mol_name]
            if len(mol_structure) == 0:
                continue

            try:
                graph_data = self._process_single_molecule(mol_name, coupling_df, mol_structure)
                if graph_data:
                    graph_data_list.extend(graph_data)
                processed_molecules += 1
            except Exception as e:
                continue

        return graph_data_list

    def _process_single_molecule(self, mol_name, coupling_df, mol_structure):
        """å¤„ç†å•ä¸ªåˆ†å­"""
        mol_structure = mol_structure.sort_values('atom_index').reset_index(drop=True)

        # åˆ›å»ºåŸå­ç‰¹å¾
        atom_features = []
        atom_coords = []

        for _, atom_row in mol_structure.iterrows():
            atom_type = atom_row['atom']
            coords = [atom_row['x'], atom_row['y'], atom_row['z']]

            # è·å–åŸå­ç‰¹å¾
            features = self.atom_features.get(atom_type, [0, 0, 0, 0, 0, 0])
            atom_features.append(features)
            atom_coords.append(coords)

        atom_features = torch.tensor(atom_features, dtype=torch.float)
        atom_coords = torch.tensor(atom_coords, dtype=torch.float)

        # åˆ›å»ºè¾¹ (ç®€å•çš„è·ç¦»é˜ˆå€¼è¿æ¥)
        edge_index, edge_attr = self._create_edges(atom_coords)

        # å¤„ç†æ¯ä¸ªåŸå­å¯¹çš„è€¦åˆå¸¸æ•°
        graph_data_list = []
        for _, coupling_row in coupling_df.iterrows():
            atom_idx_0 = coupling_row['atom_index_0']
            atom_idx_1 = coupling_row['atom_index_1']
            coupling_constant = coupling_row['scalar_coupling_constant']
            coupling_type = coupling_row['type']

            if atom_idx_0 >= len(atom_features) or atom_idx_1 >= len(atom_features):
                continue

            # åˆ›å»ºåŸå­å¯¹ç‰¹å¾
            pair_features = self._create_pair_features(
                atom_idx_0, atom_idx_1, coupling_type, atom_coords, mol_structure
            )

            # åˆ›å»ºæ•°æ®å¯¹è±¡
            data = {
                'molecule_name': mol_name,
                'atom_features': atom_features,
                'atom_coords': atom_coords,
                'edge_index': edge_index,
                'edge_attr': edge_attr,
                'pair_indices': torch.tensor([[atom_idx_0, atom_idx_1]], dtype=torch.long),
                'pair_features': pair_features,
                'pair_coords': torch.stack([atom_coords[atom_idx_0], atom_coords[atom_idx_1]]).unsqueeze(0),
                'coupling_constant': torch.tensor([coupling_constant], dtype=torch.float),
                'coupling_type': coupling_type
            }

            graph_data_list.append(data)

        return graph_data_list

    def _create_edges(self, atom_coords, cutoff=2.0):
        """åˆ›å»ºè¾¹è¿æ¥"""
        num_atoms = len(atom_coords)
        edge_list = []
        edge_distances = []

        for i in range(num_atoms):
            for j in range(i + 1, num_atoms):
                dist = torch.norm(atom_coords[i] - atom_coords[j]).item()
                if dist < cutoff:
                    edge_list.append([i, j])
                    edge_list.append([j, i])  # æ— å‘å›¾
                    edge_distances.extend([dist, dist])

        if len(edge_list) == 0:
            # å¦‚æœæ²¡æœ‰è¾¹ï¼Œåˆ›å»ºè‡ªç¯
            for i in range(num_atoms):
                edge_list.append([i, i])
                edge_distances.append(0.0)

        edge_index = torch.tensor(edge_list, dtype=torch.long).T
        edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)

        return edge_index, edge_attr

    def _create_pair_features(self, atom_idx_0, atom_idx_1, coupling_type, atom_coords, mol_structure):
        """åˆ›å»ºåŸå­å¯¹ç‰¹å¾"""
        # è·ç¦»ç‰¹å¾
        distance = torch.norm(atom_coords[atom_idx_0] - atom_coords[atom_idx_1]).item()

        # ç›¸å¯¹ä½ç½®
        rel_pos = atom_coords[atom_idx_1] - atom_coords[atom_idx_0]

        # åŸå­ç±»å‹ç¼–ç 
        atom_0_type = mol_structure.iloc[atom_idx_0]['atom']
        atom_1_type = mol_structure.iloc[atom_idx_1]['atom']

        # ç®€å•çš„åŸå­ç±»å‹ç¼–ç 
        atom_type_map = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}
        atom_0_encoded = atom_type_map.get(atom_0_type, 0)
        atom_1_encoded = atom_type_map.get(atom_1_type, 0)

        # è€¦åˆç±»å‹ç¼–ç 
        type_map = {'1JHC': 0, '2JHH': 1, '3JHH': 2, '1JCC': 3, '2JHC': 4, '2JCH': 5, '3JHC': 6}
        coupling_type_encoded = type_map.get(coupling_type, 0)

        # ç»„åˆç‰¹å¾
        features = [
            distance,
            rel_pos[0].item(), rel_pos[1].item(), rel_pos[2].item(),  # ç›¸å¯¹ä½ç½®
            atom_0_encoded, atom_1_encoded,  # åŸå­ç±»å‹
            coupling_type_encoded,  # è€¦åˆç±»å‹
            len(mol_structure)  # åˆ†å­å¤§å°
        ]

        return torch.tensor(features, dtype=torch.float).unsqueeze(0)

    def __len__(self):
        return len(self.graph_data)

    def __getitem__(self, idx):
        return self.graph_data[idx]


def custom_collate_fn(batch):
    """è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°"""
    # ç”±äºæ¯ä¸ªæ ·æœ¬éƒ½æ˜¯å•ä¸ªåŸå­å¯¹ï¼Œæˆ‘ä»¬éœ€è¦åˆå¹¶å®ƒä»¬

    all_atom_features = []
    all_atom_coords = []
    all_edge_indices = []
    all_edge_attrs = []
    all_pair_indices = []
    all_pair_features = []
    all_pair_coords = []
    all_coupling_constants = []

    atom_offset = 0

    for data in batch:
        num_atoms = data['atom_features'].shape[0]

        # åŸå­ç‰¹å¾å’Œåæ ‡
        all_atom_features.append(data['atom_features'])
        all_atom_coords.append(data['atom_coords'])

        # è¾¹ç´¢å¼•éœ€è¦åŠ åç§»
        edge_index = data['edge_index'] + atom_offset
        all_edge_indices.append(edge_index)
        all_edge_attrs.append(data['edge_attr'])

        # åŸå­å¯¹ç´¢å¼•éœ€è¦åŠ åç§»
        pair_indices = data['pair_indices'] + atom_offset
        all_pair_indices.append(pair_indices)

        all_pair_features.append(data['pair_features'])
        all_pair_coords.append(data['pair_coords'])
        all_coupling_constants.append(data['coupling_constant'])

        atom_offset += num_atoms

    # åˆå¹¶æ‰€æœ‰æ•°æ®
    batched_data = {
        'atom_features': torch.cat(all_atom_features, dim=0),
        'atom_coords': torch.cat(all_atom_coords, dim=0),
        'edge_index': torch.cat(all_edge_indices, dim=1),
        'edge_attr': torch.cat(all_edge_attrs, dim=0),
        'pair_indices': torch.cat(all_pair_indices, dim=0),
        'pair_features': torch.cat(all_pair_features, dim=0),
        'pair_coords': torch.cat(all_pair_coords, dim=0),
        'coupling_constants': torch.cat(all_coupling_constants, dim=0),
        'batch_size': len(batch)
    }

    return batched_data


# =============================================================================
# è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°
# =============================================================================
def train_coupling_model(model, train_loader, val_loader, device, num_epochs=30, model_name="Model"):
    """è®­ç»ƒè€¦åˆå¸¸æ•°é¢„æµ‹æ¨¡å‹"""
    print(f"è®­ç»ƒ {model_name} æ¨¡å‹...")

    model.to(device)
    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
    criterion = nn.MSELoss()
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=5)

    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    best_model_state = None

    start_time = time.time()

    for epoch in range(num_epochs):
        # è®­ç»ƒ
        model.train()
        train_loss = 0
        train_samples = 0

        for batch in train_loader:
            optimizer.zero_grad()

            atom_features = batch['atom_features'].to(device)
            edge_index = batch['edge_index'].to(device)
            pair_indices = batch['pair_indices'].to(device)
            pair_features = batch['pair_features'].to(device)
            targets = batch['coupling_constants'].to(device)

            # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨ä¸åŒçš„å‰å‘ä¼ æ’­
            if isinstance(model, SimpleAtomPairMLP):
                predictions = model(pair_features)
            elif isinstance(model, CouplingMPNN):
                edge_attr = batch['edge_attr'].to(device)
                predictions = model(atom_features, edge_index, edge_attr, pair_indices, pair_features)
            elif isinstance(model, Coupling3DGCN):
                atom_coords = batch['atom_coords'].to(device)
                pair_coords = batch['pair_coords'].to(device)
                predictions = model(atom_features, atom_coords, edge_index, pair_indices, pair_features, pair_coords)
            else:
                predictions = model(atom_features, edge_index, pair_indices, pair_features)

            loss = criterion(predictions.squeeze(), targets)
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

            optimizer.step()

            train_loss += loss.item() * len(targets)
            train_samples += len(targets)

        # éªŒè¯
        model.eval()
        val_loss = 0
        val_samples = 0

        with torch.no_grad():
            for batch in val_loader:
                atom_features = batch['atom_features'].to(device)
                edge_index = batch['edge_index'].to(device)
                pair_indices = batch['pair_indices'].to(device)
                pair_features = batch['pair_features'].to(device)
                targets = batch['coupling_constants'].to(device)

                if isinstance(model, SimpleAtomPairMLP):
                    predictions = model(pair_features)
                elif isinstance(model, CouplingMPNN):
                    edge_attr = batch['edge_attr'].to(device)
                    predictions = model(atom_features, edge_index, edge_attr, pair_indices, pair_features)
                elif isinstance(model, Coupling3DGCN):
                    atom_coords = batch['atom_coords'].to(device)
                    pair_coords = batch['pair_coords'].to(device)
                    predictions = model(atom_features, atom_coords, edge_index, pair_indices, pair_features, pair_coords)
                else:
                    predictions = model(atom_features, edge_index, pair_indices, pair_features)

                loss = criterion(predictions.squeeze(), targets)
                val_loss += loss.item() * len(targets)
                val_samples += len(targets)

        train_loss /= train_samples
        val_loss /= val_samples

        train_losses.append(train_loss)
        val_losses.append(val_loss)

        scheduler.step(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_state = model.state_dict().copy()

        if (epoch + 1) % 10 == 0:
            print(f'  Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}')

    # åŠ è½½æœ€ä½³æ¨¡å‹
    if best_model_state:
        model.load_state_dict(best_model_state)

    training_time = time.time() - start_time

    return {
        'model': model,
        'train_losses': train_losses,
        'val_losses': val_losses,
        'best_val_loss': best_val_loss,
        'training_time': training_time,
        'num_parameters': sum(p.numel() for p in model.parameters())
    }


def evaluate_coupling_model(model, test_loader, device):
    """è¯„ä¼°è€¦åˆå¸¸æ•°é¢„æµ‹æ¨¡å‹"""
    model.eval()
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for batch in test_loader:
            atom_features = batch['atom_features'].to(device)
            edge_index = batch['edge_index'].to(device)
            pair_indices = batch['pair_indices'].to(device)
            pair_features = batch['pair_features'].to(device)
            targets = batch['coupling_constants'].to(device)

            if isinstance(model, SimpleAtomPairMLP):
                predictions = model(pair_features)
            elif isinstance(model, CouplingMPNN):
                edge_attr = batch['edge_attr'].to(device)
                predictions = model(atom_features, edge_index, edge_attr, pair_indices, pair_features)
            elif isinstance(model, Coupling3DGCN):
                atom_coords = batch['atom_coords'].to(device)
                pair_coords = batch['pair_coords'].to(device)
                predictions = model(atom_features, atom_coords, edge_index, pair_indices, pair_features, pair_coords)
            else:
                predictions = model(atom_features, edge_index, pair_indices, pair_features)

            all_predictions.extend(predictions.squeeze().cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

    predictions = np.array(all_predictions)
    targets = np.array(all_targets)

    mae = mean_absolute_error(targets, predictions)
    mse = mean_squared_error(targets, predictions)
    rmse = np.sqrt(mse)
    r2 = r2_score(targets, predictions)

    return {
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'R2': r2,
        'predictions': predictions,
        'targets': targets
    }


# =============================================================================
# æ¯”è¾ƒæ¡†æ¶ä¸»å‡½æ•°
# =============================================================================
def compare_coupling_models(data_path='/Users/xiaotingzhou/Downloads/GNN/Dataset/scalar_coupling_constant',
                          max_samples=3000, test_split=0.2, val_split=0.1):
    """æ¯”è¾ƒä¸åŒçš„æ ‡é‡è€¦åˆå¸¸æ•°é¢„æµ‹æ¨¡å‹"""

    print("=" * 80)
    print("ğŸš€ å¼€å§‹æ ‡é‡è€¦åˆå¸¸æ•°GNNæ¡†æ¶æ¯”è¾ƒ")
    print("=" * 80)

    # è®¾å¤‡é€‰æ‹©
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ•°æ®é›†
    print("\nğŸ“Š åŠ è½½æ•°æ®é›†...")
    dataset = CouplingGraphDataset(data_path, max_samples=max_samples)

    # æ•°æ®åˆ’åˆ†
    total_size = len(dataset)
    test_size = int(total_size * test_split)
    val_size = int(total_size * val_split)
    train_size = total_size - test_size - val_size

    print(f"æ•°æ®åˆ’åˆ†: è®­ç»ƒé›†={train_size}, éªŒè¯é›†={val_size}, æµ‹è¯•é›†={test_size}")

    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size, test_size]
    )

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=custom_collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=custom_collate_fn)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=custom_collate_fn)

    # è·å–ç‰¹å¾ç»´åº¦
    sample_data = dataset[0]
    num_atom_features = sample_data['atom_features'].shape[1]
    num_pair_features = sample_data['pair_features'].shape[1]

    print(f"åŸå­ç‰¹å¾ç»´åº¦: {num_atom_features}, åŸå­å¯¹ç‰¹å¾ç»´åº¦: {num_pair_features}")

    # å®šä¹‰æ¨¡å‹é…ç½®
    models_config = {
        'SimpleAtomPairMLP': {
            'model': SimpleAtomPairMLP(num_features=num_pair_features, hidden_dim=64),
            'description': 'åŸºç¡€åŸå­å¯¹MLP'
        },
        'CouplingGCN': {
            'model': CouplingGCN(num_atom_features, num_pair_features, hidden_dim=128, num_layers=3),
            'description': 'å›¾å·ç§¯ç½‘ç»œ'
        },
        'CouplingGAT': {
            'model': CouplingGAT(num_atom_features, num_pair_features, hidden_dim=128, num_layers=3, heads=4),
            'description': 'å›¾æ³¨æ„åŠ›ç½‘ç»œ'
        },
        'CouplingTransformer': {
            'model': CouplingTransformer(num_atom_features, num_pair_features, hidden_dim=128, num_layers=2, heads=8),
            'description': 'Graph Transformer'
        },
        'CouplingMPNN': {
            'model': CouplingMPNN(num_atom_features, num_pair_features, hidden_dim=128, num_layers=3),
            'description': 'æ¶ˆæ¯ä¼ é€’ç¥ç»ç½‘ç»œ'
        },
        'Coupling3DGCN': {
            'model': Coupling3DGCN(num_atom_features, num_pair_features, hidden_dim=128, num_layers=3),
            'description': '3Då‡ ä½•å¢å¼ºGCN'
        },
        'CouplingEnsemble': {
            'model': CouplingEnsemble(num_atom_features, num_pair_features, hidden_dim=96),
            'description': 'é›†æˆå­¦ä¹ æ¨¡å‹'
        }
    }

    # è®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰æ¨¡å‹
    results = {}

    for model_name, config in models_config.items():
        print(f"\n{'='*60}")
        print(f"ğŸ”¥ è®­ç»ƒæ¨¡å‹: {model_name} - {config['description']}")
        print(f"{'='*60}")

        try:
            # è®­ç»ƒæ¨¡å‹
            training_result = train_coupling_model(
                config['model'], train_loader, val_loader, device,
                num_epochs=25, model_name=model_name
            )

            # è¯„ä¼°æ¨¡å‹
            eval_result = evaluate_coupling_model(training_result['model'], test_loader, device)

            # åˆå¹¶ç»“æœ
            results[model_name] = {
                **training_result,
                **eval_result,
                'description': config['description']
            }

            print(f"âœ… {model_name} å®Œæˆ!")
            print(f"   MAE: {eval_result['MAE']:.4f}")
            print(f"   RÂ²: {eval_result['R2']:.4f}")
            print(f"   å‚æ•°é‡: {training_result['num_parameters']:,}")
            print(f"   è®­ç»ƒæ—¶é—´: {training_result['training_time']:.1f}s")

        except Exception as e:
            print(f"âŒ {model_name} è®­ç»ƒå¤±è´¥: {str(e)}")
            results[model_name] = {'error': str(e)}

    # ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
    print(f"\n{'='*80}")
    print("ğŸ“‹ æ ‡é‡è€¦åˆå¸¸æ•°GNNæ¨¡å‹æ¯”è¾ƒç»“æœ")
    print(f"{'='*80}")

    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    valid_results = {k: v for k, v in results.items() if 'error' not in v}

    if valid_results:
        # æŒ‰MAEæ’åº
        sorted_results = sorted(valid_results.items(), key=lambda x: x[1]['MAE'])

        print(f"\nğŸ† æ¨¡å‹æ€§èƒ½æ’å (æŒ‰MAE):")
        print("-" * 80)
        print(f"{'æ’å':<4} {'æ¨¡å‹':<20} {'MAE':<8} {'RÂ²':<8} {'å‚æ•°é‡':<10} {'è®­ç»ƒæ—¶é—´':<10} {'æè¿°':<15}")
        print("-" * 80)

        for i, (model_name, result) in enumerate(sorted_results, 1):
            print(f"{i:<4} {model_name:<20} {result['MAE']:<8.4f} {result['R2']:<8.4f} "
                  f"{result['num_parameters']:<10,} {result['training_time']:<10.1f}s "
                  f"{result['description']:<15}")

        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_results = {}
        for model_name, result in valid_results.items():
            detailed_results[model_name] = {
                'MAE': result['MAE'],
                'RMSE': result['RMSE'],
                'R2': result['R2'],
                'num_parameters': result['num_parameters'],
                'training_time': result['training_time'],
                'description': result['description']
            }

        # åˆ›å»ºå¯è§†åŒ–
        create_coupling_comparison_plots(detailed_results, valid_results)

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° coupling_comparison_results.txt")
        save_coupling_results(detailed_results)

    else:
        print("âŒ æ²¡æœ‰æ¨¡å‹æˆåŠŸè®­ç»ƒå®Œæˆ")

    return results


def create_coupling_comparison_plots(results, full_results):
    """åˆ›å»ºæ ‡é‡è€¦åˆå¸¸æ•°æ¯”è¾ƒå¯è§†åŒ–"""

    if len(results) < 2:
        print("ç»“æœå¤ªå°‘ï¼Œè·³è¿‡å¯è§†åŒ–")
        return

    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('æ ‡é‡è€¦åˆå¸¸æ•°GNNæ¨¡å‹æ¯”è¾ƒ', fontsize=16, fontweight='bold')

    models = list(results.keys())
    maes = [results[m]['MAE'] for m in models]
    r2s = [results[m]['R2'] for m in models]
    params = [results[m]['num_parameters'] for m in models]
    times = [results[m]['training_time'] for m in models]

    # 1. MAEå¯¹æ¯”
    axes[0, 0].bar(models, maes, color='skyblue', alpha=0.7)
    axes[0, 0].set_title('å¹³å‡ç»å¯¹è¯¯å·® (MAE) æ¯”è¾ƒ')
    axes[0, 0].set_ylabel('MAE')
    axes[0, 0].tick_params(axis='x', rotation=45)

    # 2. RÂ²å¯¹æ¯”
    axes[0, 1].bar(models, r2s, color='lightgreen', alpha=0.7)
    axes[0, 1].set_title('å†³å®šç³»æ•° (RÂ²) æ¯”è¾ƒ')
    axes[0, 1].set_ylabel('RÂ²')
    axes[0, 1].tick_params(axis='x', rotation=45)

    # 3. å‚æ•°é‡å¯¹æ¯”
    axes[1, 0].bar(models, params, color='orange', alpha=0.7)
    axes[1, 0].set_title('æ¨¡å‹å‚æ•°é‡æ¯”è¾ƒ')
    axes[1, 0].set_ylabel('å‚æ•°æ•°é‡')
    axes[1, 0].tick_params(axis='x', rotation=45)

    # 4. è®­ç»ƒæ—¶é—´å¯¹æ¯”
    axes[1, 1].bar(models, times, color='salmon', alpha=0.7)
    axes[1, 1].set_title('è®­ç»ƒæ—¶é—´æ¯”è¾ƒ')
    axes[1, 1].set_ylabel('æ—¶é—´ (ç§’)')
    axes[1, 1].tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.savefig('coupling_gnn_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

    # åˆ›å»ºæ€§èƒ½-æ•ˆç‡æ•£ç‚¹å›¾
    fig, ax = plt.subplots(1, 1, figsize=(10, 8))

    scatter = ax.scatter(params, maes, c=times, s=100, alpha=0.7, cmap='viridis')

    for i, model in enumerate(models):
        ax.annotate(model, (params[i], maes[i]), xytext=(5, 5),
                   textcoords='offset points', fontsize=9)

    ax.set_xlabel('æ¨¡å‹å‚æ•°é‡')
    ax.set_ylabel('MAE')
    ax.set_title('æ¨¡å‹æ€§èƒ½ vs å¤æ‚åº¦ (é¢œè‰²è¡¨ç¤ºè®­ç»ƒæ—¶é—´)')

    cbar = plt.colorbar(scatter)
    cbar.set_label('è®­ç»ƒæ—¶é—´ (ç§’)')

    plt.tight_layout()
    plt.savefig('coupling_performance_efficiency.png', dpi=300, bbox_inches='tight')
    plt.show()

    # é¢„æµ‹æ•ˆæœå¯è§†åŒ–
    if 'CouplingGAT' in full_results:
        create_prediction_scatter_plot(full_results['CouplingGAT'])


def create_prediction_scatter_plot(result):
    """åˆ›å»ºé¢„æµ‹vsçœŸå®å€¼æ•£ç‚¹å›¾"""
    predictions = result['predictions']
    targets = result['targets']

    fig, ax = plt.subplots(1, 1, figsize=(8, 8))

    ax.scatter(targets, predictions, alpha=0.6, s=20)

    # ç»˜åˆ¶ç†æƒ³çº¿
    min_val = min(targets.min(), predictions.min())
    max_val = max(targets.max(), predictions.max())
    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='ç†æƒ³é¢„æµ‹')

    ax.set_xlabel('çœŸå®å€¼')
    ax.set_ylabel('é¢„æµ‹å€¼')
    ax.set_title(f'GATæ¨¡å‹é¢„æµ‹æ•ˆæœ (RÂ² = {result["R2"]:.4f})')
    ax.legend()

    plt.tight_layout()
    plt.savefig('coupling_prediction_scatter.png', dpi=300, bbox_inches='tight')
    plt.show()


def save_coupling_results(results):
    """ä¿å­˜æ¯”è¾ƒç»“æœåˆ°æ–‡ä»¶"""
    with open('coupling_comparison_results.txt', 'w', encoding='utf-8') as f:
        f.write("æ ‡é‡è€¦åˆå¸¸æ•°GNNæ¨¡å‹æ¯”è¾ƒç»“æœ\n")
        f.write("=" * 50 + "\n\n")

        # æŒ‰MAEæ’åº
        sorted_results = sorted(results.items(), key=lambda x: x[1]['MAE'])

        f.write("æ¨¡å‹æ€§èƒ½æ’å (æŒ‰MAE):\n")
        f.write("-" * 50 + "\n")

        for i, (model_name, result) in enumerate(sorted_results, 1):
            f.write(f"{i}. {model_name} ({result['description']})\n")
            f.write(f"   MAE: {result['MAE']:.6f}\n")
            f.write(f"   RMSE: {result['RMSE']:.6f}\n")
            f.write(f"   RÂ²: {result['R2']:.6f}\n")
            f.write(f"   å‚æ•°é‡: {result['num_parameters']:,}\n")
            f.write(f"   è®­ç»ƒæ—¶é—´: {result['training_time']:.1f}s\n\n")


if __name__ == "__main__":
    # è¿è¡Œæ¯”è¾ƒ
    results = compare_coupling_models(
        max_samples=3000,  # å‡å°‘æ ·æœ¬æ•°é‡ä»¥åŠ å¿«é€Ÿåº¦
        test_split=0.2,
        val_split=0.1
    )